{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_Sumarizacao.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM9FLdObD1RVyhSiSCM0C/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ufrpe-ensino/curso-mineracao-textos/blob/master/13_Sumarizacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE5-X72FOSNl",
        "colab_type": "text"
      },
      "source": [
        "# Sumarização automática\n",
        "\n",
        "(adaptado de https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70)\n",
        "\n",
        "A sumarização pode ser definida como a *tarefa de produzir um resumo conciso e fluente, preservando as informações-chave e o significado geral.*\n",
        "\n",
        "Neste demo, utilizaremos uma técnica conhecida como **TextRank**. O TextRank não depende de nenhum dado de treinamento anterior e pode funcionar com qualquer pedaço de texto arbitrário. Ele é um algoritmo de classificação baseado em **grafos** de propósito geral para NLP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g3hARX7PkYM",
        "colab_type": "text"
      },
      "source": [
        "## Importando dependências"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBtMmPTbORen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.cluster.util import cosine_distance\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV8zbdRoQMN-",
        "colab_type": "text"
      },
      "source": [
        "## Dados de teste\n",
        "\n",
        "Inglês:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbbcO-zMOUPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O msft.txt https://raw.githubusercontent.com/edubey/text-summarizer/master/msft.txt\n",
        "!cat msft.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzBEx7NnQoIH",
        "colab_type": "text"
      },
      "source": [
        "Português:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZLrjykcQd9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('machado')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import machado\n",
        "print(machado.readme()[:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1gtIKDyRmFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dom_casmurro = machado.raw('romance/marm08.txt')\n",
        "dom_casmurro[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97zhFUznRvwC",
        "colab_type": "text"
      },
      "source": [
        "## Pré processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_33UCxj0SCiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "msft_pp = open('msft.txt', \"r\").readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0q-kQwQSwpQ",
        "colab_type": "text"
      },
      "source": [
        "## Similarity matrix\n",
        "Cada sentença será representada como um vetor de BoW binário, e similaridade entre elas será dada pela distância de cosseno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4erBDl4JSCmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        " \n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        " \n",
        "    all_words = list(set(sent1 + sent2))\n",
        " \n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        " \n",
        "    # build the vector for the first sentence\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        " \n",
        "    # build the vector for the second sentence\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        " \n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        "    \n",
        "def build_similarity_matrix(sentences, stop_words):\n",
        "  # Create an empty similarity matrix\n",
        "  similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "  for idx1 in range(len(sentences)):\n",
        "    for idx2 in range(len(sentences)):\n",
        "      if idx1 == idx2: #ignore if both are same sentences\n",
        "        continue \n",
        "    similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "  return similarity_matrix\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47UpVcswTvKb",
        "colab_type": "text"
      },
      "source": [
        "## Text Rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu0-iV5KTxEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_summary(sentences, language='english', top_n=5):\n",
        "  stop_words = stopwords.words(language)\n",
        "  summarize_text = []\n",
        "\n",
        "  # Step 2 - Generate Similary Martix across sentences\n",
        "  sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "  # Step 3 - Rank sentences in similarity martix\n",
        "  sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "  scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "  # Step 4 - Sort the rank and pick top sentences\n",
        "  ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
        "  print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
        "\n",
        "  for i in range(top_n):\n",
        "    summarize_text.append(\"\".join(ranked_sentence[i][1]))\n",
        "\n",
        "  return \". \".join(summarize_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AuDY2KGT_rl",
        "colab_type": "text"
      },
      "source": [
        "## Testando!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9FA5pbeUBbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "language  = 'english'\n",
        "text      = open('msft.txt', \"r\").read()\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "print('TEXTO:')\n",
        "display(text)\n",
        "\n",
        "\n",
        "summary = generate_summary(sentences, language='english', top_n=3)\n",
        "print('SUMARIO:')\n",
        "display(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNK_F5tYUBgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "language  = 'portuguese'\n",
        "text      = dom_casmurro\n",
        "sentences = sent_tokenize(text[50:5000])\n",
        "\n",
        "print('TEXTO:')\n",
        "display(text[50:5000])\n",
        "\n",
        "\n",
        "summary = generate_summary(sentences, language='english', top_n=5)\n",
        "print('SUMARIO:')\n",
        "display(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOyCn7OEVORO",
        "colab_type": "text"
      },
      "source": [
        "# Sumy\n",
        "\n",
        "O [Sumy](https://pypi.org/project/sumy/) é uma biblioteca em python que implementa diversos métodos de sumarização extrativa, como por exemplo:\n",
        "\n",
        "* Luhn - heurestic method\n",
        "* Edmundson heurestic method with previous statistic research\n",
        "* Latent Semantic Analysis, LSA \n",
        "* LexRank - Unsupervised approach inspired by algorithms PageRank and HITS,\n",
        "* TextRank - Unsupervised approach, also using PageRank algorithm\n",
        "* SumBasic - Method that is often used as a baseline in the literature\n",
        "* KL-Sum - Method that greedily adds sentences to a summary so long as it \n",
        "* Reduction - Graph-based summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqYfroj6UBmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sumy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtbgR6MyWB5D",
        "colab_type": "text"
      },
      "source": [
        "## Testando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feMr8bfzWFEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sumy.parsers.html import HtmlParser\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer \n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "\n",
        "from sumy.nlp.stemmers import Stemmer\n",
        "from sumy.utils import get_stop_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ3cyDdeXBRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "SENTENCES_COUNT = 3\n",
        "language = 'english'\n",
        "text      = open('msft.txt', \"r\").read()\n",
        "\n",
        "parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
        "stemmer = Stemmer(language)\n",
        "\n",
        "# summarizer = LsaSummarizer(stemmer)\n",
        "summarizer = LexRankSummarizer(stemmer)\n",
        "\n",
        "summarizer.stop_words = get_stop_words(language)\n",
        "\n",
        "summary = []\n",
        "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
        "    summary.append(sentence)\n",
        "\n",
        "''.join(str(summary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUGAZ2MNYHjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SENTENCES_COUNT = 3\n",
        "language = 'portuguese'\n",
        "\n",
        "url = \"https://globoesporte.globo.com/motor/formula-1/noticia/temporada-2020-pode-ser-a-mais-cara-da-historia-da-formula-1-preve-diretor-da-rbr.ghtml\"\n",
        "parser = HtmlParser.from_url(url, Tokenizer(language))\n",
        "\n",
        "summarizer = LsaSummarizer(stemmer)\n",
        "summarizer.stop_words = get_stop_words(language)\n",
        "\n",
        "summary = []\n",
        "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
        "    summary.append(sentence)\n",
        "\n",
        "''.join(str(summary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XRLTRkSOnlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = dom_casmurro[50:5000]\n",
        "SENTENCES_COUNT = 3\n",
        "language = 'portuguese'\n",
        "\n",
        "parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
        "stemmer = Stemmer(language)\n",
        "\n",
        "# summarizer = LsaSummarizer(stemmer)\n",
        "summarizer = LexRankSummarizer(stemmer)\n",
        "\n",
        "summarizer.stop_words = get_stop_words(language)\n",
        "\n",
        "summary = []\n",
        "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
        "    summary.append(sentence)\n",
        "\n",
        "''.join(str(summary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TySHswYvudlD",
        "colab_type": "text"
      },
      "source": [
        "# Exercício\n",
        "\n",
        "Solicite ao usuário que digite (ou cole) uma URL de uma notícia na web (por exemplo, do site g1.com.br). \n",
        "\n",
        "Utilize a propriedade `parser.document.words` do `sumy` para contar quantas palavras existem no documento original, e apresente o resultado final após o processo de sumarização."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhEu33SSQdQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}